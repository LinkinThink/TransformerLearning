{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#安装所需依赖\n",
    "#!pip install -r requirements.txt\n",
    "#嵌入模型下载链接：https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.zh.300.vec.gz\n",
    "#下载后解压"
   ],
   "id": "f05d3e9b9a0a32eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Transformer结构图\n",
    "\n",
    "<img src=\"transformer结构.png\" alt=\"结构图\" width=\"400\" height=\"200\">\n",
    "\n",
    "\n",
    "根据结构，可以将整个transformer分成以下部分：\n",
    "- 输入\n",
    "    - 词嵌入\n",
    "    - 位置编码\n",
    "- Encoder\n",
    "    - 多头自注意力机制\n",
    "    - 残差连接与层归一化\n",
    "    - FFN\n",
    "- Decoder\n",
    "    - 掩码自注意力机制\n",
    "    - 交叉注意力机制\n",
    "    - 其余与Encoder相同"
   ],
   "id": "5b1539e448467276"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.词嵌入与位置编码\n",
    "- 调用FastText嵌入模型\n",
    "- 将句子转为tokens,转成向量\n",
    "- 编写位置编码函数"
   ],
   "id": "8971172876caa66f"
  },
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 加载 .vec 文件（注意 binary=False ）\n",
    "#.vec文件是文本格式，可直接查看。 但由于数据量大，解析速度会很慢，需等待比较长时间（在我的电脑上是3分半左右）\n",
    "embedded_model = KeyedVectors.load_word2vec_format(\"cc.zh.300.vec\", binary=False)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49d5d624b7671886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T09:25:25.331579Z",
     "start_time": "2025-05-13T09:25:25.308829Z"
    }
   },
   "source": [
    "#.vec文件第一行是词汇表大小和模型维度\n",
    "def get_vocab_size(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        print(f\"第一行内容：{first_line}\")\n",
    "        parts = first_line.split()\n",
    "        if len(parts) == 2:\n",
    "            vocab_size, vector_dim = map(int, parts)\n",
    "            print(f\"词汇表大小: {vocab_size}\")\n",
    "            print(f\"词向量维度: {vector_dim}\")\n",
    "        else:\n",
    "            print(\"该文件可能没有头部信息，需要手动统计。\")\n",
    "        return vocab_size, vector_dim\n",
    "\n",
    "\n",
    "vocab_size, d_model = get_vocab_size('cc.zh.300.vec')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一行内容：2000000 300\n",
      "词汇表大小: 2000000\n",
      "词向量维度: 300\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d290ff0a3a67d2c6",
   "metadata": {},
   "source": [
    "#1.1 模型测试与基本操作\n",
    "\n",
    "#查询词向量\n",
    "word_vector = embedded_model[\"春风\"]\n",
    "print(f\"word vector shape: {word_vector.shape}\")\n",
    "\n",
    "#找出于指定词最相似的5个词\n",
    "print(f\"最接近的词:{embedded_model.most_similar('国王', topn=5)}\")\n",
    "\n",
    "#计算两个词的余弦相似度\n",
    "similarity = embedded_model.similarity('男人', '女人')\n",
    "print(f\"相似度:{similarity}\")\n",
    "\n",
    "#类比推理  国王 + 女人 - 男人\n",
    "result = embedded_model.most_similar(positive=['国王', '女人'], negative=['男人'],topn=5)\n",
    "result\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f4700a22e6d3c2d",
   "metadata": {},
   "source": [
    "#可视化词向量  将词向量降维到2维\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = ['king', 'queen', 'man', 'woman','dog','cat','apple','banana']\n",
    "vectors = [embedded_model[word] for word in words]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(vectors)\n",
    "\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff952807edf4fb89",
   "metadata": {},
   "source": [
    "#1.2 分词，转成词向量\n",
    "import jieba\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def sentence_to_vectors_verbose(sentence, model):\n",
    "    #jieba分词\n",
    "    tokens = list(jieba.cut(sentence))\n",
    "    vectors = []\n",
    "    tokens_info = []\n",
    "\n",
    "    #将分词结果嵌入成向量\n",
    "    for token in tokens:\n",
    "        token_vectors, token_labels = get_token_vector_recursive_verbose(token, model)\n",
    "        vectors.extend(token_vectors)\n",
    "        tokens_info.extend(token_labels)\n",
    "\n",
    "    return vectors, tokens_info\n",
    "\n",
    "def get_token_vector_recursive_verbose(token, model):\n",
    "    \"\"\"\n",
    "    递归获取token向量，同时记录是直接命中还是细分。\n",
    "    \"\"\"\n",
    "    if token in model:\n",
    "        return [model[token]], [{'token': token, 'source': 'direct'}]\n",
    "    elif len(token) == 1:\n",
    "        return [], [{'token': token, 'source': 'OOV'}]  # 可以选择用UNK\n",
    "    else:\n",
    "        sub_vectors = []\n",
    "        sub_info = []\n",
    "        for char in token:\n",
    "            if char in model:\n",
    "                sub_vectors.append(model[char])\n",
    "                sub_info.append({'token': char, 'source': 'split'})\n",
    "            else:\n",
    "                sub_info.append({'token': char, 'source': 'OOV'})\n",
    "        return sub_vectors, sub_info\n",
    "\n",
    "\n",
    "# 测试句子\n",
    "sentence = \"今天天气不错\"\n",
    "sentence_vectors, tokens_info = sentence_to_vectors_verbose(sentence, embedded_model)\n",
    "\n",
    "# 展示分词与来源\n",
    "print(\"分词与处理信息：\")\n",
    "for info in tokens_info:\n",
    "    print(f\"{info['token']} - {info['source']}\")\n",
    "\n",
    "print(f\"\\n总向量数: {len(sentence_vectors)}\")\n",
    "print(f\"每个向量维度: {sentence_vectors[0].size if sentence_vectors else '无向量'}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebe4ac19fb78f4f",
   "metadata": {},
   "source": [
    "#1.3 位置编码\n",
    "import numpy as np\n",
    "\n",
    "#输入为句子长度与向量维度\n",
    "def positional_encoding(seq_len, dim):\n",
    "    pos_enc = np.zeros((seq_len, dim))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(0, dim, 2):\n",
    "            pos_enc[pos, i] = np.sin(pos / (10000 ** ((2 * i) / dim)))\n",
    "            if i + 1 < dim:\n",
    "                pos_enc[pos, i + 1] = np.cos(pos / (10000 ** ((2 * i) / dim)))\n",
    "    return pos_enc  # shape: (seq_len, dim)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2eac7eb45e1e71bd",
   "metadata": {},
   "source": [
    "#可视化位置编码结果——使用热力图，低维捕捉高频信息颜色变化剧烈，反之高维颜色变化缓慢\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_vectors(vectors):\n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(vectors, cmap='YlGnBu', cbar=True, xticklabels=10, yticklabels=10)\n",
    "    plt.title(\"Position Encoding Heatmap\")\n",
    "    plt.xlabel(\"Dimensions\")\n",
    "    plt.ylabel(\"Sequence Position\")\n",
    "    plt.show()\n",
    "\n",
    "# 测试,生成50个句子，维度300\n",
    "plot_vectors(positional_encoding(50,300))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98ebd13f49788a3d",
   "metadata": {},
   "source": [
    "#原句子向量加上位置编码\n",
    "embedded_vectors = sentence_vectors + positional_encoding(len(sentence_vectors), sentence_vectors[0].size)\n",
    "print(embedded_vectors.shape)\n",
    "\n",
    "#将输入格式转成(batch_size,sentence_len,dim),且转成torch下的tensor\n",
    "import torch\n",
    "embed_tensor = torch.tensor(embedded_vectors)\n",
    "embed_tensor = embed_tensor.unsqueeze(0).float()  #这里输入只有一句，直接将batch_size设为1\n",
    "print(embed_tensor.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bebaa33aad0ff74d",
   "metadata": {},
   "source": [
    "## 2.多头注意力机制\n",
    "- 生成Q,K,V矩阵，拆分多头\n",
    "- 计算注意力得分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1caec7ce8be3ffd",
   "metadata": {},
   "source": [
    "注意力计算方式： $$ Attention = Softmax(\\frac{Q*K^T}{\\sqrt{dK}}) *V$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "47ad73ab584a9b86",
   "metadata": {},
   "source": [
    "#2.1 多头自注意力机制\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self,d_model,n_head,dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0,\"d_model 必须能被n_head整除\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head       #注意力头数\n",
    "        self.head_dim = d_model // n_head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #qkv：输入的线性映射 o：输出\n",
    "        self.q = nn.Linear(d_model,d_model)\n",
    "        self.k = nn.Linear(d_model,d_model)\n",
    "        self.v = nn.Linear(d_model,d_model)\n",
    "        self.o = nn.Linear(d_model,d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size ,seq_len ,d_model = x.size()\n",
    "        # print(f\"batch_size:{batch_size},seq_len:{seq_len},d_model:{d_model}\")\n",
    "\n",
    "        #拆分为多头 x.shape = (batch_size,seq_len,n_head,d_model),这里先将d_model拆分成n_head*head_dim,为了方便计算，再将seq_len和n_head的位置交换\n",
    "        #最终格式是(batch_size,n_head,seq_len,head_dim)\n",
    "        Q = self.q(x).view(batch_size,seq_len,self.n_head,self.head_dim).transpose(1, 2)\n",
    "        K = self.k(x).view(batch_size,seq_len,self.n_head,self.head_dim).transpose(1, 2)\n",
    "        V = self.v(x).view(batch_size,seq_len,self.n_head,self.head_dim).transpose(1, 2)\n",
    "\n",
    "        #计算注意力\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "        attention_scores = attention_scores / math.sqrt(self.head_dim)\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "        attention_scores = F.dropout(attention_scores)  #dropout,参考《Attention is all you need》原文，防止注意力过拟合\n",
    "        attention_output = torch.matmul(attention_scores, V)\n",
    "\n",
    "        #合并 与拆分同理，要注意在.view和.transpose后张量变为内存不连续（.view会改变索引方式），所以需要.contiguous进行连续化\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size,seq_len, self.d_model)\n",
    "\n",
    "        output = self.o(attention_output)\n",
    "        return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5a188dcea38280f",
   "metadata": {},
   "source": [
    "multi_attention = MultiHeadSelfAttention(d_model=embed_tensor.shape[2],n_head=5)\n",
    "atten_output = multi_attention(embed_tensor)\n",
    "print(atten_output.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30a1dd491c465bee",
   "metadata": {},
   "source": [
    "## 3.残差连接与层归一化\n",
    "- 层归一化原理\n",
    "- Pytorch残差连接与层归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc299164b9c29569",
   "metadata": {},
   "source": [
    "层归一化原理:\n",
    "- 假设输入是一个向量：$$ x = [x_1,x_2,...,x_H]$$ $$ μ = \\frac{1}{H} \\sum_{i=1}^{H} x_i $$ $$σ = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(x_i - μ)^2 + ϵ} $$\n",
    "- 归一化后： $$\\hat x_i = \\frac{x_i - μ}{σ}$$\n",
    "- 再进行缩放平移：$$ y_i =  γ \\hat x_i + β$$\n",
    "- 其中：𝛾,𝛽 是可学习参数。ϵ 是一个防止除 0 的小值"
   ]
  },
  {
   "cell_type": "code",
   "id": "73bfb1fd67febcd3",
   "metadata": {},
   "source": [
    "def layer_norm_manual(x, eps=1e-5):\n",
    "    mean = x.mean(dim=-1, keepdim=True)\n",
    "    std = x.std(dim=-1, keepdim=True)\n",
    "    return (x - mean) / (std + eps)\n",
    "\n",
    "# 示例\n",
    "x = torch.randn(32, 10, 512)\n",
    "output = layer_norm_manual(x)\n",
    "print(output.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "311ed7350a4df9ea",
   "metadata": {},
   "source": [
    "#实践中主要调用pytorch封装的函数\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设输入 (batch_size, seq_len, hidden_size)\n",
    "x = torch.randn(32, 10, 512)\n",
    "\n",
    "# 创建LayerNorm（对最后一维做归一化）\n",
    "layer_norm = nn.LayerNorm(normalized_shape=512)\n",
    "\n",
    "# 使用\n",
    "output = layer_norm(x)\n",
    "print(output.shape)  # torch.Size([32, 10, 512])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2d9a58bf1fa4474",
   "metadata": {},
   "source": [
    "#残差连接则是将上一层输出连接到当前层输出（直接相加）\n",
    "class ResidualLayerNorm(nn.Module):\n",
    "    def __init__(self,size,dropout=0.1):\n",
    "        super(ResidualLayerNorm,self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x,sublayer_output):\n",
    "        x = self.norm(x + self.dropout(sublayer_output))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed3dcee382a1cc8e",
   "metadata": {},
   "source": [
    "## 4.FFN前馈神经网络\n",
    "- 结构：$$FFN(x) = ReLu(xW_1 + b1)W_2 + b2 $$\n",
    "- 其中：$W_1$通常是4倍于输入维度，用来将输入非线性映射到更高维的信息以获得更丰富的语义表达，$W_2$降维回原来维度，ReLu是非线性激活函数\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0dac009ff87efff",
   "metadata": {},
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(d_model,d_ff)  #d_ff：隐藏层维度，通常取4倍d_model\n",
    "        self.relu = nn.ReLU()\n",
    "        self.w2 = nn.Linear(d_ff,d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.w1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.w2(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7af665af2ea5ef",
   "metadata": {},
   "source": [
    "## 5.Encoder,各模块封装整合"
   ]
  },
  {
   "cell_type": "code",
   "id": "47b1ec5aa899e030",
   "metadata": {},
   "source": [
    "class Transformer_encoder(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,n_head,dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = MultiHeadSelfAttention(d_model,n_head,dropout=dropout)\n",
    "        self.ffn = FFN(d_model,d_ff,dropout=dropout)\n",
    "        self.layer_norm_1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm_2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        atten_output = self.attention(x)\n",
    "        x = self.layer_norm_1(x + self.dropout(atten_output))\n",
    "\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.layer_norm_2(x + self.dropout(ffn_output))\n",
    "\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f03765c505de0c3",
   "metadata": {},
   "source": [
    "#结构图中，Encoder需要将上述模块重复N次\n",
    "#这里使用ModuleList实现\n",
    "class TransformerEncoderStack(nn.Module):\n",
    "    def __init__(self, n_layers, d_model, d_ff, n_head, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            Transformer_encoder(d_model, d_ff, n_head, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8bfe9c28943987f6",
   "metadata": {},
   "source": [
    "#可视化张量，热力图\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "def visualize_tensor_stages(*tensors, labels=None, title='Tensor Evolution Heatmap'):\n",
    "    \"\"\"\n",
    "    可视化多个阶段的 [batch, seq_len, d_model] 张量。\n",
    "\n",
    "    参数：\n",
    "    - *tensors: 任意数量的张量，每个形状为 [batch, seq_len, d_model]\n",
    "    - labels: 每个张量的标签（可选），用于标题显示\n",
    "    \"\"\"\n",
    "    num_tensors = len(tensors)\n",
    "    if labels is None:\n",
    "        labels = [f'Stage {i}' for i in range(num_tensors)]\n",
    "\n",
    "    batch_idx = 0  # 默认只取第一个 batch 可视化\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_tensors, figsize=(6 * num_tensors, 5))\n",
    "    if num_tensors == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, tensor in enumerate(tensors):\n",
    "        assert tensor.dim() == 3, f\"Tensor {i} must have shape [batch, seq_len, d_model]\"\n",
    "        data = tensor[batch_idx].detach().cpu().numpy()  # shape: [seq_len, d_model]\n",
    "\n",
    "        sns.heatmap(data, ax=axes[i], cmap='viridis')\n",
    "        axes[i].set_xlabel('Dimension (d_model)')\n",
    "        axes[i].set_ylabel('Token Position (seq_len)')\n",
    "        axes[i].set_title(labels[i])\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#调用案例\n",
    "# visualize_tensor_stages(embedding_out, attn_out, resnorm_out,\n",
    "#                         labels=[\"Embedding\", \"Attention Output\", \"Post-ResNorm\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e173af42c5293bf0",
   "metadata": {},
   "source": [
    "encoder = TransformerEncoderStack(n_layers=6, d_model=d_model, d_ff=4*d_model, n_head=5, dropout=0.1)\n",
    "encoder_output = encoder(embed_tensor)\n",
    "visualize_tensor_stages(embed_tensor,atten_output,encoder_output\n",
    "                        ,labels=[\"Embedding\",\"Attention\",\"Encoder_output\"])\n",
    "print(encoder_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f1cb156c5e03e149",
   "metadata": {},
   "source": [
    "## 6.掩码自注意力\n",
    "- 生成掩码矩阵，掩盖对未来值的询问"
   ]
  },
  {
   "cell_type": "code",
   "id": "a61d15c0919989e8",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaskedSelfAttention(nn.Module):\n",
    "    def __init__(self,d_model,n_head,dropout=0.1,visual=False):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0,\"d_model 必须能被n_head整除\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = d_model // n_head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #可视化开关\n",
    "        self.visual = visual\n",
    "\n",
    "        #线性映射\n",
    "        self.q = nn.Linear(d_model,d_model)\n",
    "        self.k = nn.Linear(d_model,d_model)\n",
    "        self.v = nn.Linear(d_model,d_model)\n",
    "        self.o = nn.Linear(d_model,d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size ,seq_len ,d_model = x.size()\n",
    "\n",
    "        Q = self.q(x).view(batch_size,seq_len,self.n_head,self.head_dim).transpose(1, 2)\n",
    "        K = self.k(x).view(batch_size,seq_len,self.n_head,self.head_dim).transpose(1, 2)\n",
    "        V = self.v(x).view(batch_size,seq_len,self.n_head,self.head_dim).transpose(1, 2)\n",
    "\n",
    "        #计算注意力\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "        attention_scores = attention_scores / math.sqrt(self.head_dim)\n",
    "        # 生成掩码矩阵 (下三角矩阵：mask未来信息)\n",
    "        mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).repeat(batch_size, 1, 1)  # (batch_size, seq_len, seq_len)\n",
    "        mask = (mask == 0)  # 0的部分为mask的区域\n",
    "        # 应用掩码\n",
    "        attention_scores = attention_scores.masked_fill(mask == True, -1e9)  # 掩盖上三角\n",
    "        #可视化掩盖结果\n",
    "        if self.visual:\n",
    "            visualize_tensor_stages(attention_scores[-1],title=\"masking\")\n",
    "            print(attention_scores)\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attention_scores = F.dropout(attention_scores)  #dropout\n",
    "        attention_output = torch.matmul(attention_scores, V)\n",
    "\n",
    "\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size,seq_len, self.d_model)\n",
    "\n",
    "        output = self.o(attention_output)\n",
    "        return output\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ccaf7515604aa700",
   "metadata": {},
   "source": [
    "mask_test = MaskedSelfAttention(d_model=d_model,n_head=5,dropout=0.1,visual=True)\n",
    "mask_test_output = mask_test(embed_tensor)\n",
    "# print(mask_test_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2f271c92d4b1b7f",
   "metadata": {},
   "source": [
    "## 7.交叉注意力机制\n",
    "- 生成当前的查询Q与Encoder输出的K,V"
   ]
  },
  {
   "cell_type": "code",
   "id": "f86936193b1468c0",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0, \"d_model 必须能被n_head整除\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = d_model // n_head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.q = nn.Linear(d_model, d_model)  # Decoder Query\n",
    "        self.k = nn.Linear(d_model, d_model)  # Encoder Key\n",
    "        self.v = nn.Linear(d_model, d_model)  # Encoder Value\n",
    "        self.o = nn.Linear(d_model, d_model)  # Output\n",
    "\n",
    "    #输入是前面encoder的输出和decoder前一层的输出\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        batch_size, seq_len_dec, d_model = x_dec.size()\n",
    "        batch_size, seq_len_enc, d_model  = x_enc.size()\n",
    "        # 生成 decoder的查询矩阵Q\n",
    "        Q = self.q(x_dec).view(batch_size, seq_len_dec, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        #生成 encoder的键与值K,V\n",
    "        K = self.k(x_enc).view(batch_size, seq_len_enc, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        V = self.v(x_enc).view(batch_size, seq_len_enc, self.n_head, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # 计算交叉注意力得分\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1))  # (batch_size, n_head, seq_len, seq_len)\n",
    "        attention_scores = attention_scores / math.sqrt(self.head_dim)\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # 获取注意力输出\n",
    "        attention_output = torch.matmul(attention_probs, V)  # (batch_size, n_head, seq_len, head_dim)\n",
    "\n",
    "        # 合并多头输出\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, seq_len_dec, self.d_model)\n",
    "\n",
    "        # 线性变换得到最终输出\n",
    "        output = self.o(attention_output)\n",
    "        return output\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "debb7fedca7de7d9",
   "metadata": {},
   "source": [
    "#新嵌入\n",
    "newsentence = \"明天天气如何\"\n",
    "\n",
    "new_sen_vector , _ = sentence_to_vectors_verbose(newsentence,embedded_model)\n",
    "\n",
    "#位置编码\n",
    "new_embedding = new_sen_vector + positional_encoding(len(new_sen_vector),d_model)\n",
    "# #转tensor\n",
    "new_embedding_tensor = torch.tensor(new_embedding)\n",
    "new_embedding_tensor = new_embedding_tensor.unsqueeze(0).float()      # shape: (1, seq_len, 300)\n",
    "\n",
    "new_embedding_tensor.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfdaa5f083e9e3b0",
   "metadata": {},
   "source": [
    "mask_atten = MaskedSelfAttention(new_embedding_tensor.shape[-1],n_head=5,dropout=0.1,visual=True)\n",
    "cross_atten = CrossAttention(new_embedding_tensor.shape[-1],n_head=5,dropout=0.1)\n",
    "#\n",
    "mask_atten_output = mask_atten(new_embedding_tensor)\n",
    "cross_atten_output = cross_atten(encoder_output, mask_atten_output)\n",
    "print(cross_atten_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a0964e19c0956551",
   "metadata": {},
   "source": [
    "## 8.整合Decoder部分"
   ]
  },
  {
   "cell_type": "code",
   "id": "382781875b4f7a9d",
   "metadata": {},
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,n_head,dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_selfAttention = MaskedSelfAttention(d_model=d_model,n_head=n_head,dropout=dropout)\n",
    "        self.cross_attention = CrossAttention(d_model=d_model,n_head=n_head,dropout=dropout)\n",
    "        self.ffn = FFN(d_model,d_ff,dropout=dropout)\n",
    "        self.layer_norm_1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm_2 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm_3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_enc,x):\n",
    "        mask_attention = self.mask_selfAttention(x)\n",
    "        x = self.layer_norm_1(x + self.dropout(mask_attention))\n",
    "        cross_attention = self.cross_attention(x_enc,x)\n",
    "        x = self.layer_norm_2(x + self.dropout(cross_attention))\n",
    "        ffn = self.ffn(x)\n",
    "        x = self.layer_norm_3(x + self.dropout(ffn))\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9135b2e773a66f6",
   "metadata": {},
   "source": [
    "class TransformerDecoderStack(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,n_head,n_layer,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerDecoder(d_model, d_ff, n_head, dropout) for _ in range(n_layer)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x_enc,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x_enc,x)\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e8a0583675ba875",
   "metadata": {},
   "source": [
    "decoder = TransformerDecoderStack(n_layer=6,d_model=d_model,d_ff=4*d_model,n_head=5,dropout=0.1)\n",
    "decoder_output = decoder(encoder_output,new_embedding_tensor)\n",
    "visualize_tensor_stages(encoder_output,new_embedding_tensor)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "873a4dc71d805d6d",
   "metadata": {},
   "source": [
    "## 9.最终输出\n",
    "- 输出层（线性映射），大小（词向量维度d_model,词汇表大小vocab_size）\n",
    "- 推理与训练"
   ]
  },
  {
   "cell_type": "code",
   "id": "5843ba0a6788c673",
   "metadata": {},
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self,n_layers,d_model,d_ff,n_head,vocab_size,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoderStack(n_layers=n_layers,d_model=d_model,d_ff=d_ff,n_head=n_head,dropout=dropout)\n",
    "        self.decoder = TransformerDecoderStack(n_layer=n_layers,d_model=d_model,d_ff=d_ff,n_head=n_head,dropout=dropout)\n",
    "        self.fc_out = nn.Linear(d_model,vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, src,trg):\n",
    "        enc_output = self.encoder(src)\n",
    "        dec_output = self.decoder(enc_output,trg)\n",
    "\n",
    "        output = self.fc_out(dec_output)\n",
    "        return output\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13d6b538e6d76acb",
   "metadata": {},
   "source": [
    "t = MyTransformer(n_layers=6,d_model=d_model,d_ff=4*d_model,n_head=5,dropout=0.1,vocab_size=vocab_size)\n",
    "prob_out = t(embed_tensor,new_embedding_tensor)\n",
    "print(prob_out.shape)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
